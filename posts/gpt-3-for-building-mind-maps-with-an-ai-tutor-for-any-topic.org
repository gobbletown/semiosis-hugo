#+LATEX_HEADER: \usepackage[margin=0.5in]{geometry}
#+OPTIONS: toc:nil

#+HUGO_BASE_DIR: /home/shane/var/smulliga/source/git/semiosis/semiosis-hugo
#+HUGO_SECTION: ./posts

#+TITLE: GPT-3 for building mind maps with an AI tutor for any topic
#+DATE: <2021-03-29>
#+AUTHOR: Shane Mulligan
#+KEYWORDS: GPT-3 emacs learning

** Summary
I combine GPT-3 with =org-brain= to expand on
topics, suggesting subtopics and providing an
interactive tutor for any topic.

** Demonstration
*** Learn about AI
#+BEGIN_EXPORT html
<!-- Play on asciinema.com -->
<!-- <a title="asciinema recording" href="https://asciinema.org/a/tV37yuypzU8C4ttDL4w24HOtx" target="_blank"><img alt="asciinema recording" src="https://asciinema.org/a/tV37yuypzU8C4ttDL4w24HOtx.svg" /></a> -->
<!-- Play on the blog -->
<script src="https://asciinema.org/a/tV37yuypzU8C4ttDL4w24HOtx.js" id="asciicast-tV37yuypzU8C4ttDL4w24HOtx" async></script>
#+END_EXPORT

*** Learn about microbiology
#+BEGIN_EXPORT html
<!-- Play on asciinema.com -->
<!-- <a title="asciinema recording" href="https://asciinema.org/a/R25hFKsdKc1wcfbMGeXnXa0iJ" target="_blank"><img alt="asciinema recording" src="https://asciinema.org/a/R25hFKsdKc1wcfbMGeXnXa0iJ.svg" /></a> -->
<!-- Play on the blog -->
<script src="https://asciinema.org/a/R25hFKsdKc1wcfbMGeXnXa0iJ.js" id="asciicast-R25hFKsdKc1wcfbMGeXnXa0iJ" async></script>
#+END_EXPORT

** Code
*** Subtopic prompt
#+BEGIN_SRC yaml -n :async :results verbatim code
  title: "subtopic generation"
  prompt: |+
      The following is a list of subtopics relating to microbiology:
      - Bacteriology
      - Mycology
      - Protozoology
      - Phycology/algology
      - Parasitology
      - Immunology
      - Virology
      - Nematology
      ###
      The following is a list of subtopics relating to natural language processing / NLP:
      - extractive question answering
      - language modelling
      - named entity recognition  
      - sequence classification
      - summarization
      - text generation
      - topic modelling
      - translation
      ###
      The following is a list of subtopics relating to language modelling in NLP:
      - casual language modelling
      - masked language modelling
      - gext generation
      ###
      The following is a list of subtopics relating to <1>:
      - 
  engine: "davinci"
  temperature: 0.8
  max-tokens: 60
  top-p: 1
  frequency-penalty: 0.8
  presence-penalty: 0.0
  best-of: 1
  stop-sequences:
  - "###"
  chomp-start: on
  chomp-end: off
  inject-start-text: yes
  inject-restart-text: yes
  show-probabilities: off
  # Cache the function by default when running the prompt function
  cache: on
  vars:
  - "topic"
  examples:
  - "Advanced Type Systems in Haskell"
  # External provides an alternate script that performs the same function
  # external:
  # - "extract-keyphrases"
#+END_SRC

*** =tutor= prompt
#+BEGIN_SRC python -n :i mypython :async :results verbatim code
  title: "Generic tutor for any topic"
  prompt: |+
      This is a conversation between a human and a brilliant AI.
      The topic is "<1>".
  
      Human: Hello, are you my <2> tutor?
      ###
      AI: Hi there. Yes I am. How can I help you today?
      ###
      Human: What questions can I ask you about <1>?
      ###
      AI: You may ask me anything relating to <2>.
      ###
      Human: OK then. <3>
      ###
      AI: I would be happy to answer your question.
  engine: "davinci"
  # 0.0 = /r/hadastroke
  # 1.0 = /r/iamveryrandom
  # Use 0.3-0.8
  temperature: 0.8
  max-tokens: 60
  top-p: 1.0
  # Not available yet: openai api completions.create --help
  frequency-penalty: 0.5
  # If I make presence-penalty 0 then it will get very terse
  presence-penalty: 0.0
  best-of: 3
  stop-sequences:
  - "###"
  inject-start-text: yes
  inject-restart-text: yes
  show-probabilities: off
  vars:
  - "topic"
  - "in the context of"
  - "question"
  examples:
  - "node js"
  - "programming"
  - "What was the version of node in 2018?"
  chomp-start: on
  chomp-end: off
  external: ""
  conversation-mode: no
  filter: no
  # Keep stitching together until reaching this limit
  # This allows a full response for answers which may need n*max-tokens to reach the stop-sequence.
  stitch-max: 0
  needs-work: no
#+END_SRC

*** elisp
#+BEGIN_SRC emacs-lisp -n :async :results verbatim code
  (defun org-brain-name-from-list-maybe (l)
    (if (and (listp l)
             (> (length l) 1))
        (second l)
      l))
  
  (defun org-brain-remove-irrelevant-names-from-path (path)
    (-filter
     (lambda
       (e)
       (not
        (string-equal "infogetics" e)))
     path))
  
  (defun org-brain-parent-name ()
    (snc "s join"
      (list2str
             (org-brain-remove-irrelevant-names-from-path
              (mapcar
               'org-brain-name-from-list-maybe
               (org-brain-parents org-brain--vis-entry))))))
  
  (defun org-brain-current-name ()
    (car
     (org-brain-remove-irrelevant-names-from-path
      (mapcar
       'org-brain-name-from-list-maybe
       (list org-brain--vis-entry)))))
  
  (defun org-brain-current-topic (&optional for-external-searching)
    (interactive)
    (let ((path
           (mapcar
            'org-brain-name-from-list-maybe
            (append (org-brain-parents org-brain--vis-entry) (list org-brain--vis-entry)))))
  
      (setq path
            (if for-external-searching
                (-filter (lambda (e) (not (string-equal "infogetics" e))) path)
              path))
      (let ((topic
             (chomp (apply 'cmd path))))
        (if (interactive-p)
            (etv topic)
          topic))))
  
  (defun org-brain-suggest-subtopics ()
    (interactive)
    (let ((subtopics
           (pen-pf-keyword-extraction (org-brain-current-topic t))))
      (if (interactive-p)
          (etv subtopics)
        subtopics)))
  
  (defun org-brain-asktutor (question)
    (interactive (list (read-string-hist (concat (org-brain-current-topic) ": "))))
    (mu
     (etv
      (snc
       (concat
        (cmd
         "oci"
         "openai-complete"
         "$MYGIT/semiosis/prompts/prompts/tutor.prompt"
         (org-brain-current-name)
         (org-brain-parent-name)
         question)
        " | tpp")))))
#+END_SRC

** =pen.el= improvements
- I plan on linking =.prompt= (prompt
description) files into a graph format where
fungible prompts can be observed.